---
title: Lectures 19 and 20
week: 9
lecture_date: 2022-11-28 and 2022-11-30
author: Ashwin Ranade
layout: lecture
parent: Lecture Notes
---

## Table of Contents
{: .no_toc }

{:toc}
- dummy item

## Concurrency
Concurrency is when we decompose a program into simultaneously executing tasks. 

The tasks can: 
- run in parallel on multiple cores, OR run multiplexed on a single core
- operate on independent data, OR operate on shared mutable data/systems
- be launched deterministcally through program flow, OR be lanuched to due external event (button click in UI)

Concurrency can make our programs more efficient!

**Question:** If a concurrent program only runs on a single core, why would it be any faster than a program that runs serially?
**Answer:** Some tasks involve lots of waiting, not a lot of CPU. During that waiting time, a concurrent program can use the CPU for other useful tasks!
- example: downloading a photo

### Concurrency With Shared Mutable State

#### Race Conditions

**Question:** What will the value of karma be if I run both functions concurrently until completion? Why?

```
int karma = 0;

void do_good_deeds() {
  for (int i=0;i<100000;++i)
    karma++;
}

void be_naughty() {
  for (int i=0;i<100000;++i)
    karma--;
}
```

**Answer:** Answer: Given that each "thread" of execution can be interrupted at any time to run the other, it's impossible to know!

The undefined behavior is due to both threads using a _shared mutable state_; `karma` is a mutable variable that's shared between multiple threads. 
(Race Condition)
- a key goal of concurrency is **determinism**; code should produce the same result every time, **regardless** of how its tasks are scheduled. 

#### Safe Concurrency With Shared Mutable State

Most modern languages now have built-in language features to make it safer to use shared mutable state.

For example, Java's synchronized keyword can be used to limit access to a mutable variable to a single thread at a time.

### Models for Concurrency

Two approaches for implementing concurrency: 

**Multi-threading model:** 
A program creates multiple "threads" of execution that run concurrently (potentially in parallel). 

The programmer explicitly "launches" one or more functions in their own threads, and the OS schedules their execution across available CPU cores.

```
// Multi-threaded program (pseudocode)
void handle_user_purchase(User u, Item i) {
  if (bill_credit_card(u) == SUCCESS) {
    create_thread(schedule_shipping(u, i));
    create_thread(send_confirm_email(u, i));
  }
}
```

**Event Driven Model**: 
A program consists of a queue of functions to run, and an infinite loop that dequeues and runs each function from the queue, one after the other.

When an event occurs (e.g., user clicks a button) the event results in a new function f() being added to the queue which eventually runs and handles the event.

```
// Event-driven program (pseudocode)
function process_payment() { ... }

void setup_event_associations() {
 button = create_new_button("Pay Now!");
 button.set_func(ON_CLICK, process_payment);
}
```

### Fork-Join: A Common Pattern for Multi-Threading

The "fork-join" pattern is basically a concurrent version of divide and conquer.

First, we "fork" one or more tasks so they execute concurrently...

Second, we wait for all those tasks to complete (aka "join") and then proceed.



**Example:** A parallel sort would be a good example of a problem suitable for fork-join.

```
function sort_in_parallel(array, n) {
  t1 = run_background(sort(array[0:n/3])); 
  t2 = run_background(sort(array[n/3:n*2/3)); 
  t3 = run_background(sort(array[n*2/3:n]));

  wait_for_all_tasks_to_finish(t1, t2, t3);
  merge_sorted_subarrays(array);
}
```

```
function task1(param) { ... }
function task2(param) { ... }
function task3(param1, param2) { ... }

function launch_in_parallel() {
  t1 = run_background(task1(42)); 
  t2 = run_background(task2("suss")); 
  t3 = run_background(task3(3.14, 2.71));

  wait_for_all_tasks_to_finish(t1, t2, t3);
  print("All tasks completed, proceeding...");
}
```

Fork-Join is Often Used Recursively. 

#### Fork-Join In Different Languages

```
// C++
#include <thread>          
 
void task1(int n)  { ... }
void task2(int n)  { ... }
void task3(int n)  { ... }

int main() {
  std::cout << "Forking threads!\n";
  //To launch a function in the background, we simply create a new thread object.

  std::thread t1(task1, 10);
  std::thread t2(task2, 20);
  std::thread t3(task3, 30);

  // do other processing here...

  t1.join(); //To join, we simple call the thread.join() method. This blocks the caller until the thread finishes.

  t2.join();
  t3.join();
  std::cout << "All threads joined!\n";
}
```


```
# Python
import threading

def task(n):
  while n > 0:   # do some computation
    n = n - 1

print("Forking threads!")

#In Python, we must create a thread object, and then do thread.start() before it runs.

t1 = threading.Thread(target=task, args=(100000000,))
t2 = threading.Thread(target=task, args=(100000000,))
t3 = threading.Thread(target=task, args=(100000000,))
t1.start()
t2.start()
t3.start()

# do other processing here...

t1.join()
t2.join()
t3.join()
print("All threads joined!")
```
#### Multi-threading in Python
**Question for the Python program:**
Assuming looping 100 million times takes 5s, how long will this program take to run on a multicore PC?

**Answer**: 15s
We'd expect all three tasks to run in parallel... taking 5s total. But it takes 15s! 
Why? Because when each Python thread runs, it claims exclusive access to Python's memory/objects.

So only one thread generally does computation at a time!

Why? Python's garbage collection system was never designed to be thread-safe!

Python has something called a "Global Interpreter Lock" or GIL.

The GIL is like a hot potato â€“ it can only have one owner at a time.

Once a thread takes ownership of the GIL it's allowed to read/write to Python objects.

After a thread runs for a while, it releases the GIL (tosses the potato) to another thread and gives it ownership.

If a thread is waiting for the GIL, it simply falls asleep until it gets its turn.

**Question:** So why even support multiple threads? Are there any cases where multithreading speeds things up?

**Answer:** Answer: I/O operations like downloading data from the web or saving a file to disk DON'T need the GIL to run! So these kinds of operations can still make progress if launched in the background!








